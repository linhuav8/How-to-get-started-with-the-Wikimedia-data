{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11363773,"sourceType":"datasetVersion","datasetId":7112711}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to get started with the Wikimedia data","metadata":{}},{"cell_type":"markdown","source":"The [Wikipedia Structured Contents](https://www.kaggle.com/datasets/wikimedia-foundation/wikipedia-structured-contents) dataset on Kaggle contains all articles of the English and French language editions of Wikipedia, pre-parsed and outputted as structured JSON files with a consistent schema. Each JSON line holds the content of one full Wikipedia article stripped of extra markdown and non-prose sections (references, etc.).\n\nThe data is divided into multiple large `.jsonl` files. Here we will explore just one of those files: `./wikipedia-structured-contents/enwiki_namespace_0/enwiki_namespace_0_0.jsonl`.","metadata":{}},{"cell_type":"markdown","source":"## Initial Setup\n","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport os\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport re\nfrom wordcloud import WordCloud\nimport networkx as nx\nfrom textblob import TextBlob\nimport nltk\nfrom nltk.corpus import stopwords\n\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['figure.dpi'] = 100\nsns.set(style=\"whitegrid\")\n\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T19:40:53.14146Z","iopub.execute_input":"2025-04-21T19:40:53.141766Z","iopub.status.idle":"2025-04-21T19:40:59.231941Z","shell.execute_reply.started":"2025-04-21T19:40:53.141737Z","shell.execute_reply":"2025-04-21T19:40:59.231003Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"def read_jsonl(file_path, max_records=None):\n    data = []\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(tqdm(f)):\n            if max_records and i >= max_records:\n                break\n            data.append(json.loads(line))\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:40:59.232912Z","iopub.execute_input":"2025-04-21T19:40:59.233485Z","iopub.status.idle":"2025-04-21T19:40:59.239171Z","shell.execute_reply.started":"2025-04-21T19:40:59.233455Z","shell.execute_reply":"2025-04-21T19:40:59.23794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\nfile_path = kagglehub.dataset_download(\"wikimedia-foundation/wikipedia-structured-contents\",path=\"enwiki_namespace_0/enwiki_namespace_0_0.jsonl\")\ndata = read_jsonl(file_path)\nprint(f\"Successfully loaded {len(data)} records\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:40:59.24144Z","iopub.execute_input":"2025-04-21T19:40:59.241802Z","iopub.status.idle":"2025-04-21T19:42:17.191688Z","shell.execute_reply.started":"2025-04-21T19:40:59.241773Z","shell.execute_reply":"2025-04-21T19:42:17.190832Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preview Data","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data)\nprint(f\"Dataset shape: {df.shape}\")\nprint(\"\\nColumns in the dataset:\")\nfor col in df.columns:\n    print(f\"- {col}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:17.19272Z","iopub.execute_input":"2025-04-21T19:42:17.193064Z","iopub.status.idle":"2025-04-21T19:42:19.780296Z","shell.execute_reply.started":"2025-04-21T19:42:17.193031Z","shell.execute_reply":"2025-04-21T19:42:19.779332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSample data:\")\ndisplay(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:19.781679Z","iopub.execute_input":"2025-04-21T19:42:19.782013Z","iopub.status.idle":"2025-04-21T19:42:19.831482Z","shell.execute_reply.started":"2025-04-21T19:42:19.781989Z","shell.execute_reply":"2025-04-21T19:42:19.830664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Dates","metadata":{}},{"cell_type":"code","source":"date_fields = ['date_modified']\nfor date_field in date_fields:\n    if date_field in df.columns:\n        try:\n            df[date_field] = pd.to_datetime(df[date_field])\n            df[f'{date_field}_year'] = df[date_field].dt.year\n            df[f'{date_field}_month'] = df[date_field].dt.month\n            df[f'{date_field}_day'] = df[date_field].dt.day\n            df[f'{date_field}_hour'] = df[date_field].dt.hour\n            df[f'{date_field}_weekday'] = df[date_field].dt.day_name()\n        except Exception as e:\n            print(f\"Could not convert {date_field} to datetime: {e}\")\n\nfor date_field in date_fields:\n    if date_field in df.columns:\n        \n        # Distribution by year\n        if f'{date_field}_year' in df.columns:\n            plt.figure(figsize=(14, 6))\n            year_counts = df[f'{date_field}_year'].value_counts().sort_index()\n            year_counts.plot(kind='bar')\n            plt.title(f'Distribution by Year ({date_field})', fontsize=14)\n            plt.xlabel('Year', fontsize=12)\n            plt.ylabel('Count', fontsize=12)\n            plt.xticks(rotation=45)\n            plt.show()\n        \n        # Distribution by month\n        if f'{date_field}_month' in df.columns:\n            plt.figure(figsize=(14, 6))\n            month_counts = df[f'{date_field}_month'].value_counts().sort_index()\n            month_names = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', \n                           7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n            month_counts.index = month_counts.index.map(lambda x: month_names.get(x, x))\n            month_counts.plot(kind='bar')\n            plt.title(f'Distribution by Month ({date_field})', fontsize=14)\n            plt.xlabel('Month', fontsize=12)\n            plt.ylabel('Count', fontsize=12)\n            plt.show()\n        \n        # Distribution by day of week\n        if f'{date_field}_weekday' in df.columns:\n            plt.figure(figsize=(14, 6))\n            day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n            weekday_counts = df[f'{date_field}_weekday'].value_counts()\n            weekday_counts = weekday_counts.reindex(day_order)\n            weekday_counts.plot(kind='bar')\n            plt.title(f'Distribution by Day of Week ({date_field})', fontsize=14)\n            plt.xlabel('Day of Week', fontsize=12)\n            plt.ylabel('Count', fontsize=12)\n            plt.show()\n        \n        # Distribution by hour\n        if f'{date_field}_hour' in df.columns:\n            plt.figure(figsize=(14, 6))\n            hour_counts = df[f'{date_field}_hour'].value_counts().sort_index()\n            hour_counts.plot(kind='bar')\n            plt.title(f'Distribution by Hour of Day ({date_field})', fontsize=14)\n            plt.xlabel('Hour', fontsize=12)\n            plt.ylabel('Count', fontsize=12)\n            plt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:19.832488Z","iopub.execute_input":"2025-04-21T19:42:19.832834Z","iopub.status.idle":"2025-04-21T19:42:21.810993Z","shell.execute_reply.started":"2025-04-21T19:42:19.832811Z","shell.execute_reply":"2025-04-21T19:42:21.806716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Names","metadata":{}},{"cell_type":"code","source":"# Analysis for name field\nif 'name' in df.columns:\n    \n    # Word frequency in names\n    all_names = ' '.join(df['name'].dropna().astype(str))\n    words = re.findall(r'\\b\\w+\\b', all_names.lower())\n    stop_words = set(stopwords.words('english'))\n    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n    name_word_freq = Counter(filtered_words)\n    \n    # Display top words\n    print(\"Most common words in names:\")\n    for word, count in name_word_freq.most_common(15):\n        print(f\"  {word}: {count}\")\n    \n    # Word cloud for names\n    plt.figure(figsize=(14, 7))\n    name_cloud = WordCloud(width=800, height=400,\n                         background_color='white',\n                         max_words=100).generate(' '.join(filtered_words))\n    plt.imshow(name_cloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title('Word Cloud of Names', fontsize=14)\n    plt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:21.812029Z","iopub.execute_input":"2025-04-21T19:42:21.812314Z","iopub.status.idle":"2025-04-21T19:42:30.493163Z","shell.execute_reply.started":"2025-04-21T19:42:21.812289Z","shell.execute_reply":"2025-04-21T19:42:30.492227Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Descriptions","metadata":{}},{"cell_type":"code","source":"# Analysis for description field\nif 'description' in df.columns:\n    \n    # Handle descriptions as strings or lists/dicts\n    descriptions = []\n    for desc in df['description'].dropna():\n        if isinstance(desc, str):\n            descriptions.append(desc)\n        elif isinstance(desc, list):\n            descriptions.extend([d for d in desc if isinstance(d, str)])\n    \n    # Word frequency in descriptions\n    all_descriptions = ' '.join(descriptions)\n    words = re.findall(r'\\b\\w+\\b', all_descriptions.lower())\n    filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n    desc_word_freq = Counter(filtered_words)\n    \n    # Display top words\n    print(\"Most common words in descriptions:\")\n    for word, count in desc_word_freq.most_common(15):\n        print(f\"  {word}: {count}\")\n    \n    # Word cloud for descriptions\n    plt.figure(figsize=(14, 7))\n    desc_cloud = WordCloud(width=800, height=400,\n                         background_color='white',\n                         max_words=100).generate(' '.join(filtered_words))\n    plt.imshow(desc_cloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title('Word Cloud of Descriptions', fontsize=14)\n    plt.show()\n    \n    # Description length analysis\n    desc_lengths = [len(d) for d in descriptions]\n    plt.figure(figsize=(14, 6))\n    sns.histplot(desc_lengths, bins=20, kde=True)\n    plt.title('Distribution of Description Lengths', fontsize=14)\n    plt.xlabel('Character Length', fontsize=12)\n    plt.ylabel('Frequency', fontsize=12)\n    plt.show()\n    \n    print(f\"Average description length: {np.mean(desc_lengths):.1f} characters\")","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:30.494216Z","iopub.execute_input":"2025-04-21T19:42:30.494523Z","iopub.status.idle":"2025-04-21T19:42:37.853321Z","shell.execute_reply.started":"2025-04-21T19:42:30.494497Z","shell.execute_reply":"2025-04-21T19:42:37.852381Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Abstracts","metadata":{}},{"cell_type":"code","source":"if 'abstract' in df.columns:\n    \n    # Handle abstracts as strings or lists/dicts\n    abstracts = []\n    for abstract in df['abstract'].dropna():\n        if isinstance(abstract, str):\n            abstracts.append(abstract)\n        elif isinstance(abstract, list):\n            abstracts.extend([a for a in abstract if isinstance(a, str)])\n\n    abstract_lengths = [len(a) for a in abstracts]\n    print(f\"Average abstract length: {np.mean(abstract_lengths):.1f} characters\")\n    \n    # Word cloud for abstracts\n    if abstracts:\n        all_abstracts = ' '.join(abstracts)\n        words = re.findall(r'\\b\\w+\\b', all_abstracts.lower())\n        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n        \n        plt.figure(figsize=(14, 7))\n        abstract_cloud = WordCloud(width=800, height=400,\n                                 background_color='white',\n                                 max_words=100).generate(' '.join(filtered_words))\n        plt.imshow(abstract_cloud, interpolation='bilinear')\n        plt.axis('off')\n        plt.title('Word Cloud of Abstracts', fontsize=14)\n        plt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-21T19:42:37.85543Z","iopub.execute_input":"2025-04-21T19:42:37.85572Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Sections","metadata":{}},{"cell_type":"code","source":"if 'sections' in df.columns:\n    \n    # Count number of sections per record\n    section_counts = []\n    section_names = []\n    \n    for sections in df['sections'].dropna():\n        if isinstance(sections, list):\n            section_counts.append(len(sections))\n            # Extract section names (assuming sections is a list of dicts with 'name' key)\n            for section in sections:\n                if isinstance(section, dict) and 'name' in section:\n                    section_names.append(section['name'])\n    \n    # Top section names\n    if section_names:\n        section_name_counts = Counter(section_names)\n        \n        plt.figure(figsize=(14, 7))\n        pd.Series(section_name_counts).nlargest(15).plot(kind='bar')\n        plt.title('Top 15 Section Names', fontsize=14)\n        plt.xlabel('Section Name', fontsize=12)\n        plt.ylabel('Count', fontsize=12)\n        plt.xticks(rotation=45, ha='right')\n        plt.show()\n        \n        display(pd.Series(section_name_counts).nlargest(15))\n","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Explore Images","metadata":{}},{"cell_type":"code","source":"if 'image' in df.columns:\n    \n    # Count number of records with images\n    image_present = df['image'].notna()\n    image_count = image_present.sum()\n    no_image_count = (~image_present).sum()\n    \n    print(f\"Records with images: {image_count} ({image_count/len(df)*100:.1f}%)\")\n    print(f\"Records without images: {no_image_count} ({no_image_count/len(df)*100:.1f}%)\")\n    \n    # Visualize image presence distribution\n    plt.figure(figsize=(10, 6))\n    plt.bar(['Has Image', 'No Image'], [image_count, no_image_count], color=['green', 'red'])\n    plt.title('Distribution of Records with and without Images', fontsize=14)\n    plt.ylabel('Count', fontsize=12)\n    plt.show()\n","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
